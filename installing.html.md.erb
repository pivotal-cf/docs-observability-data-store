---
title: Installing Observability Data Store for PCF
owner: Primus
---

This topic describes how to install and configure Observability Data Store for Pivotal Cloud Foundry (PCF). For a list of compatible Ops Manager, Pivotal Application Service (PAS)  and Pivotal Container Service (PKS) versions, see [Product Snapshot](index.html#snapshot).

##<a id='install'></a> Install Observability Data Store for PCF

1. Download the product file from [Pivotal Network](https://network.pivotal.io/products/observability_datastore_pcf).

1. Navigate to the Ops Manager Installation Dashboard and click **Import a Product** to upload the product file.

1. Under the **Import a Product** button, click **+** next to the version number of Observability Data Store for PCF.
This adds the tile to your staging area.

##<a id='configure'></a> Configure Observability Data Store for PCF

To start using Observability Data Store for PCF, you need to configure the Observability Data Store for PCF tile.

### <a id='observability-data-store-tile'></a> Configure the Observability Data Store for PCF Tile

To configure the Observability Data Store for PCF tile, perform the following steps:

1. Click the **Observability Data Store for PCF** tile on the Ops Manager Installation Dashboard.
1. Navigate to **Assign AZs and Networks** and do the following:
    1. Select an Availability Zone (AZ) for placing singleton jobs.
    1. Select one or more AZs for balancing other jobs.

		<p class="note"><strong>Note</strong>: To create a highly available environment, Pivotal recommends selecting multiple AZs.</p>

    1. Select **Network** for installing Observability Data Store for PCF.
    1. Click **Save**.

1. Navigate to **Prometheus Configuration** and do the following:
    1. Optional: Modify the **Scrape Interval** as desired. This controls the frequency at which Prometheus scrapes its targets for metrics.
    1. Ensure that **Integrate with PAS** is set as appropriate. It should be enabled if PAS is *already* installed on the foundation.

1. Navigate to **Telegraf Configuration** and do the following:
    1. Optional: Modify the **Scrape Port** as desired. This controls the port on which Telegraf exposes metrics. It should only be changed if that port is already in use by other components on the VM.

1. Navigate to **Errands** and do the following:
    1. Optional: Enable or disable the **Smoke Tests** errand. This errand verifies that the tile is functioning correctly, and ideally should not be disabled.

1. Return to the Ops Manager Installation Dashboard and click **Apply Changes**.

### <a id='observability-data-store-tile'></a> (Optional) Backing Up Observability Data Store for PCF

Observability Data Store for PCF supports (Bosh Backup and Restore)[https://docs.pivotal.io/pivotalcf/2-4/customizing/backup-restore/index.html] functionality.
We recommend running nightly backup via a Concourse pipeline job like the one below:

```yaml
---
resource_types:
  - name: gcs-resource
    type: docker-image
    source:
      repository: frodenas/gcs-resource

  - name: pivnet
    type: docker-image
    source:
      repository: pivotalcf/pivnet-resource
      tag: latest-final

resources:
  - name: bbr-release
    type: pivnet
    source:
      api_token: ((pivnet-refresh-token))
      product_slug: p-bosh-backup-and-restore

  - name: bbr-pipeline-tasks-repo
    type: git
    source:
      uri: https://github.com/pivotal-cf/bbr-pcf-pipeline-tasks.git
      branch: master
      tag_filter: v1.0.0

  - name: bbr-docker
    type: docker-image
    source:
      repository: cloudfoundrylondon/bbr-pipeline
      tag: final

  - name: nightly
    type: time
    source:
      interval: 24h
      start: 22:00
      stop: 00:00
      location: America/Denver

  - name: ods-backup-bucket
    type: gcs-resource
    source:
      bucket: ((gcs-bucket-name))
      json_key: ((service-account-json))
      regexp: ((gcs-directory))/ods-backup-(.*).tar

jobs:
  - name: trigger-backup
    plan:
      - put: nightly

  - name: nightly-backup
    plan:
      - aggregate:
        - get: nightly
          trigger: true
        - get: bbr-docker
        - get: bbr-release
        - get: bbr-pipeline-tasks-repo
      - task: extract-binary
        file: bbr-pipeline-tasks-repo/tasks/extract-bbr-binary/task.yml
      - task: run-backup
        image: bbr-docker
        config:
          platform: linux

          inputs:
            - name: binary
            - name: bbr-pipeline-tasks-repo

          outputs:
            - name: ods-backup-artifact

          params:
            OPSMAN_URL: ((opsman-url))
            OPSMAN_USERNAME: ((opsman-user.username))
            OPSMAN_PASSWORD: ((opsman-user.password))
            OPSMAN_PRIVATE_KEY: ((ops-man-ssh-key.private_key))

          run:
            path: /bin/bash
            args:
              - -c
              - |
                #!/usr/bin/env bash

                set -eu

                scripts="${PWD}/bbr-pipeline-tasks-repo/scripts"

                export CLIENT_ID=
                # shellcheck disable=SC1090
                source "${scripts}/export-director-metadata"

                om_cmd curl -p /api/v0/deployed/products > deployed_products.json
                DEPLOYMENT_NAME=$(jq -r '.[] | select(.type == "p-observability-data-store") | .guid' "deployed_products.json")
                export DEPLOYMENT_NAME

                pushd ods-backup-artifact
                  ${scripts}/deployment-backup
                  tar -cvf ods-backup-$(date +%Y.%m.%d.%H.%M.%S).tar -- *
                popd

      - put: ods-backup-bucket
        params:
          file: ods-backup-artifact/ods-backup-*.tar
```
